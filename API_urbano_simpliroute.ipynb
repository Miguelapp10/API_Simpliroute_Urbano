{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Miguelapp10/API_Simpliroute_Urbano/blob/main/API_urbano_simpliroute.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWHDoIOiAUuN",
        "outputId": "71a3dc86-c6d6-4fa7-c02f-3311446225a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-119f1b9b6d9f>:128: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_visits_selected['Observaciones'] = df_visits_selected['checkout_observation'].apply(map_observation_to_new_column)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 7294.44it/s]\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point, LineString\n",
        "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
        "from google.colab import files\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "import warnings\n",
        "\n",
        "# Suprimir sólo las advertencias de InsecureRequestWarning\n",
        "warnings.filterwarnings('ignore', category=InsecureRequestWarning)\n",
        "\n",
        "# Información de autenticación\n",
        "token = ''\n",
        "base_url_vehicles = 'https://api.simpliroute.com/v1/routes/vehicles/'\n",
        "base_url_routes = 'https://api.simpliroute.com/v1/routes/routes/'\n",
        "base_url_visits = 'https://api.simpliroute.com/v1/routes/visits/'\n",
        "\n",
        "# Encabezados de la solicitud\n",
        "headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "    'Authorization': f'Token {token}'\n",
        "}\n",
        "\n",
        "# Función para generar un rango de fechas\n",
        "def date_range(start_date, end_date):\n",
        "    for n in range(int((end_date - start_date).days) + 1):\n",
        "        yield start_date + timedelta(n)\n",
        "\n",
        "# Definir el rango de fechas\n",
        "start_date = datetime.strptime('2024-04-01', '%Y-%m-%d')\n",
        "end_date = datetime.today()  # Usar la fecha actual para end_date\n",
        "\n",
        "# Función para obtener datos de una URL en una fecha específica\n",
        "def fetch_data_for_date(base_url, single_date):\n",
        "    formatted_date = single_date.strftime('%Y-%m-%d')\n",
        "    url = f'{base_url}?planned_date={formatted_date}'\n",
        "\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        try:\n",
        "            response_data = response.json()\n",
        "            if response_data:\n",
        "                return response_data  # Devolver los datos obtenidos\n",
        "        except json.JSONDecodeError:\n",
        "            return []\n",
        "    return []\n",
        "\n",
        "# Función para obtener datos de una URL en un rango de fechas usando ThreadPoolExecutor\n",
        "def get_data_parallel(base_url, start_date, end_date):\n",
        "    all_data = []\n",
        "    dates = list(date_range(start_date, end_date))\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "        futures = [executor.submit(fetch_data_for_date, base_url, date) for date in dates]\n",
        "        for future in futures:\n",
        "            result = future.result()\n",
        "            if result:\n",
        "                all_data.extend(result)\n",
        "\n",
        "    return all_data\n",
        "\n",
        "# Obtener datos de ambos endpoints en paralelo\n",
        "all_vehicles_data = get_data_parallel(base_url_vehicles, start_date, end_date)\n",
        "all_routes_data = get_data_parallel(base_url_routes, start_date, end_date)\n",
        "all_visits_data = get_data_parallel(base_url_visits, start_date, end_date)\n",
        "\n",
        "# Convertir todos los datos a DataFrames de pandas\n",
        "df_vehicles = pd.json_normalize(all_vehicles_data)\n",
        "df_routes = pd.json_normalize(all_routes_data)\n",
        "df_visits = pd.json_normalize(all_visits_data)\n",
        "\n",
        "# Seleccionar las columnas deseadas de cada DataFrame\n",
        "df_vehicles_selected = df_vehicles[['id','name',\n",
        "                                    #'capacity','capacity_2','default_driver','location_start_address',\n",
        "                                    #'location_start_latitude','location_start_longitude','location_end_address',\n",
        "                                    #'location_end_latitude','location_end_longitude','created','modified',\n",
        "                                    'color']].drop_duplicates()\n",
        "# Renombrar la columna 'id' a 'vehicle'\n",
        "df_vehicles_selected = df_vehicles_selected.rename(columns={'id': 'vehicle'})\n",
        "\n",
        "df_routes_selected = df_routes[['id','vehicle','driver','plan','status','planned_date','estimated_time_start',\n",
        "                                'estimated_time_end','total_duration','total_distance','total_load','total_load_percentage',\n",
        "                                'location_start_address','location_start_latitude','location_start_longitude',\n",
        "                                'location_end_address','location_end_latitude','location_end_longitude','start_time',\n",
        "                                'end_time','created','modified','kilometers','total_visits','latitude_init','longitude_init',\n",
        "                                'latitude_finish','longitude_finish'\n",
        "]].drop_duplicates()  # Reemplaza 'other_columns' con las columnas deseadas de df_routes\n",
        "# Renombrar la columna 'id' a 'vehicle'\n",
        "df_routes_selected = df_routes_selected.rename(columns={'id': 'route','status':'status_route','created':'created_route','modified':'modified_route'})\n",
        "\n",
        "# Seleccionar las columnas deseadas\n",
        "selected_columns = ['id', 'order', 'tracking_id', 'status', 'title', 'address',  'latitude', 'longitude',\n",
        "                    #'load', 'load_2', 'load_3', 'window_start', 'window_end', 'window_start_2', 'window_end_2', 'duration',\n",
        "                        'contact_name', 'contact_phone', 'reference', 'notes', 'planned_date', 'route',\n",
        "                        'route_estimated_time_start', 'estimated_time_arrival', 'estimated_time_departure', 'checkin_time',\n",
        "                        'checkout_time', 'checkout_latitude', 'checkout_longitude', 'checkout_comment',\n",
        "                        'checkout_observation',# 'signature','pictures',\n",
        "                        'created', 'modified', 'eta_predicted',\n",
        "                        'eta_current', 'driver', 'vehicle', 'on_its_way']\n",
        "df_visits_selected = df_visits[selected_columns]\n",
        "\n",
        "\n",
        "# Función para mapear valores de checkout_observation a una nueva columna\n",
        "def map_observation_to_new_column(observation):\n",
        "    mapping = {\n",
        "        '1a1d65aa-d355-45b6-8c3f-3f2295ee4c5a':'Producto no corresponde',\n",
        "        '56a04e5b-2fc5-42df-b4dc-6ef75d97f63c':'Cliente no quiere identificarse',\n",
        "        '6084c66c-c720-4136-b20f-e01c80a73378':'Fallas mecánicas',\n",
        "        '830808ee-2ef6-4c96-973c-751d530ba0f9':'Entregado a conserje',\n",
        "        '9dc634d3-865f-470b-92c0-14fb63a40637':'Fuera De Horario',\n",
        "        'e4d21dd5-1107-4c99-a9b7-fae1bac83882':'Entregado a familiar',\n",
        "        'f97966aa-47f5-4c4d-8d42-1b6df9729157':'Entregado a titular',\n",
        "        'c505bc38-1215-48bf-9e6b-d78bce3dc2f2':'Cliente Solicito Reprogramación',\n",
        "        '8c15fdad-2f27-49eb-9967-f4fa94a366b1':'Entregado en tienda',\n",
        "        '04902a7e-116c-4083-82bb-2849e1928db3':'Cliente Ausente',\n",
        "        'fe8ac91f-0ead-4d84-b33c-aa094173d32b':'Domicilio Sin Acceso',\n",
        "        '2fee0a67-e6d8-4742-ac52-f8c4f0382543':'Rechazado Por Cliente',\n",
        "        '412375a8-cd64-4e8a-81be-5572ca883018':'Producto Dañado'\n",
        "        }\n",
        "    return mapping.get(observation, 'Otro')\n",
        "\n",
        "# Aplicar la función al DataFrame\n",
        "df_visits_selected['Observaciones'] = df_visits_selected['checkout_observation'].apply(map_observation_to_new_column)\n",
        "\n",
        "# Unir los DataFrames en el campo común 'vehicle'\n",
        "df_routes_vehicles = pd.merge(df_routes_selected, df_vehicles_selected, on='vehicle', how='inner')\n",
        "\n",
        "# Unir los DataFrames en el campo común 'vehicle'\n",
        "df_visits_routes_vehicles = pd.merge(df_visits_selected, df_routes_vehicles, on=('vehicle','driver' ,'route', 'planned_date'), how='left')\n",
        "\n",
        "project_id = 'bi-fcom-drmb-local-pe-sbx'\n",
        "!gcloud config set project {project_id}\n",
        "# Configuración del dataset y la tabla en BigQuery\n",
        "dataset_id = 'Pidgeotto_Devolucion'\n",
        "table_id = 'SimpliRoute_visits_IL'\n",
        "#table_id_2 = 'SimpliRoute_routes_IL'\n",
        "# Cliente de BigQuery\n",
        "client = bigquery.Client(project=project_id)\n",
        "# Cargar el DataFrame en BigQuery\n",
        "df_visits_routes_vehicles.to_gbq(destination_table=f'{dataset_id}.{table_id}', project_id=project_id, if_exists='replace')\n",
        "# Cargar el DataFrame en BigQuery\n",
        "#gdf.to_gbq(destination_table=f'{dataset_id}.{table_id_2}', project_id=project_id, if_exists='replace')\n",
        "# Mostrar el resultado\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRTQDHnCjErP",
        "outputId": "468bfca6-b8d9-461d-f065-11586f92622e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-d25c0c5f088c>:159: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['movimiento_fecha'] = pd.to_datetime(df['movimiento_fecha'], errors='coerce')\n",
            "<ipython-input-2-d25c0c5f088c>:159: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['movimiento_fecha'] = pd.to_datetime(df['movimiento_fecha'], errors='coerce')\n",
            "<ipython-input-2-d25c0c5f088c>:159: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['movimiento_fecha'] = pd.to_datetime(df['movimiento_fecha'], errors='coerce')\n",
            "<ipython-input-2-d25c0c5f088c>:160: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['estado_actual_fecha_hora'] = pd.to_datetime(df['estado_actual_fecha'] + \" \" + df['estado_actual_hora'],  errors='coerce')\n",
            "<ipython-input-2-d25c0c5f088c>:159: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['movimiento_fecha'] = pd.to_datetime(df['movimiento_fecha'], errors='coerce')\n",
            "<ipython-input-2-d25c0c5f088c>:159: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['movimiento_fecha'] = pd.to_datetime(df['movimiento_fecha'], errors='coerce')\n",
            "<ipython-input-2-d25c0c5f088c>:159: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['movimiento_fecha'] = pd.to_datetime(df['movimiento_fecha'], errors='coerce')\n",
            "<ipython-input-2-d25c0c5f088c>:159: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['movimiento_fecha'] = pd.to_datetime(df['movimiento_fecha'], errors='coerce')\n",
            "<ipython-input-2-d25c0c5f088c>:159: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['movimiento_fecha'] = pd.to_datetime(df['movimiento_fecha'], errors='coerce')\n",
            "<ipython-input-2-d25c0c5f088c>:159: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['movimiento_fecha'] = pd.to_datetime(df['movimiento_fecha'], errors='coerce')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 576.30it/s]\n"
          ]
        }
      ],
