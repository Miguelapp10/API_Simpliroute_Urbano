{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Miguelapp10/API_Simpliroute_Urbano/blob/main/API_urbano_simpliroute.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWHDoIOiAUuN",
        "outputId": "71a3dc86-c6d6-4fa7-c02f-3311446225a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-119f1b9b6d9f>:128: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_visits_selected['Observaciones'] = df_visits_selected['checkout_observation'].apply(map_observation_to_new_column)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 7294.44it/s]\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point, LineString\n",
        "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
        "from google.colab import files\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "import warnings\n",
        "\n",
        "# Suprimir sólo las advertencias de InsecureRequestWarning\n",
        "warnings.filterwarnings('ignore', category=InsecureRequestWarning)\n",
        "\n",
        "# Información de autenticación\n",
        "token = ''\n",
        "base_url_vehicles = 'https://api.simpliroute.com/v1/routes/vehicles/'\n",
        "base_url_routes = 'https://api.simpliroute.com/v1/routes/routes/'\n",
        "base_url_visits = 'https://api.simpliroute.com/v1/routes/visits/'\n",
        "\n",
        "# Encabezados de la solicitud\n",
        "headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "    'Authorization': f'Token {token}'\n",
        "}\n",
        "\n",
        "# Función para generar un rango de fechas\n",
        "def date_range(start_date, end_date):\n",
        "    for n in range(int((end_date - start_date).days) + 1):\n",
        "        yield start_date + timedelta(n)\n",
        "\n",
        "# Definir el rango de fechas\n",
        "start_date = datetime.strptime('2024-04-01', '%Y-%m-%d')\n",
        "end_date = datetime.today()  # Usar la fecha actual para end_date\n",
        "\n",
        "# Función para obtener datos de una URL en una fecha específica\n",
        "def fetch_data_for_date(base_url, single_date):\n",
        "    formatted_date = single_date.strftime('%Y-%m-%d')\n",
        "    url = f'{base_url}?planned_date={formatted_date}'\n",
        "\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        try:\n",
        "            response_data = response.json()\n",
        "            if response_data:\n",
        "                return response_data  # Devolver los datos obtenidos\n",
        "        except json.JSONDecodeError:\n",
        "            return []\n",
        "    return []\n",
        "\n",
        "# Función para obtener datos de una URL en un rango de fechas usando ThreadPoolExecutor\n",
        "def get_data_parallel(base_url, start_date, end_date):\n",
        "    all_data = []\n",
        "    dates = list(date_range(start_date, end_date))\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "        futures = [executor.submit(fetch_data_for_date, base_url, date) for date in dates]\n",
        "        for future in futures:\n",
        "            result = future.result()\n",
        "            if result:\n",
        "                all_data.extend(result)\n",
        "\n",
        "    return all_data\n",
        "\n",
        "# Obtener datos de ambos endpoints en paralelo\n",
        "all_vehicles_data = get_data_parallel(base_url_vehicles, start_date, end_date)\n",
        "all_routes_data = get_data_parallel(base_url_routes, start_date, end_date)\n",
        "all_visits_data = get_data_parallel(base_url_visits, start_date, end_date)\n",
        "\n",
        "# Convertir todos los datos a DataFrames de pandas\n",
        "df_vehicles = pd.json_normalize(all_vehicles_data)\n",
        "df_routes = pd.json_normalize(all_routes_data)\n",
        "df_visits = pd.json_normalize(all_visits_data)\n",
        "\n",
        "# Seleccionar las columnas deseadas de cada DataFrame\n",
        "df_vehicles_selected = df_vehicles[['id','name',\n",
        "                                    #'capacity','capacity_2','default_driver','location_start_address',\n",
        "                                    #'location_start_latitude','location_start_longitude','location_end_address',\n",
        "                                    #'location_end_latitude','location_end_longitude','created','modified',\n",
        "                                    'color']].drop_duplicates()\n",
        "# Renombrar la columna 'id' a 'vehicle'\n",
        "df_vehicles_selected = df_vehicles_selected.rename(columns={'id': 'vehicle'})\n",
        "\n",
        "df_routes_selected = df_routes[['id','vehicle','driver','plan','status','planned_date','estimated_time_start',\n",
        "                                'estimated_time_end','total_duration','total_distance','total_load','total_load_percentage',\n",
        "                                'location_start_address','location_start_latitude','location_start_longitude',\n",
        "                                'location_end_address','location_end_latitude','location_end_longitude','start_time',\n",
        "                                'end_time','created','modified','kilometers','total_visits','latitude_init','longitude_init',\n",
        "                                'latitude_finish','longitude_finish'\n",
        "]].drop_duplicates()  # Reemplaza 'other_columns' con las columnas deseadas de df_routes\n",
        "# Renombrar la columna 'id' a 'vehicle'\n",
        "df_routes_selected = df_routes_selected.rename(columns={'id': 'route','status':'status_route','created':'created_route','modified':'modified_route'})\n",
        "\n",
        "# Seleccionar las columnas deseadas\n",
        "selected_columns = ['id', 'order', 'tracking_id', 'status', 'title', 'address',  'latitude', 'longitude',\n",
        "                    #'load', 'load_2', 'load_3', 'window_start', 'window_end', 'window_start_2', 'window_end_2', 'duration',\n",
        "                        'contact_name', 'contact_phone', 'reference', 'notes', 'planned_date', 'route',\n",
        "                        'route_estimated_time_start', 'estimated_time_arrival', 'estimated_time_departure', 'checkin_time',\n",
        "                        'checkout_time', 'checkout_latitude', 'checkout_longitude', 'checkout_comment',\n",
        "                        'checkout_observation',# 'signature','pictures',\n",
        "                        'created', 'modified', 'eta_predicted',\n",
        "                        'eta_current', 'driver', 'vehicle', 'on_its_way']\n",
        "df_visits_selected = df_visits[selected_columns]\n",
        "\n",
        "\n",
        "# Función para mapear valores de checkout_observation a una nueva columna\n",
        "def map_observation_to_new_column(observation):\n",
        "    mapping = {\n",
        "        '1a1d65aa-d355-45b6-8c3f-3f2295ee4c5a':'Producto no corresponde',\n",
        "        '56a04e5b-2fc5-42df-b4dc-6ef75d97f63c':'Cliente no quiere identificarse',\n",
        "        '6084c66c-c720-4136-b20f-e01c80a73378':'Fallas mecánicas',\n",
        "        '830808ee-2ef6-4c96-973c-751d530ba0f9':'Entregado a conserje',\n",
        "        '9dc634d3-865f-470b-92c0-14fb63a40637':'Fuera De Horario',\n",
        "        'e4d21dd5-1107-4c99-a9b7-fae1bac83882':'Entregado a familiar',\n",
        "        'f97966aa-47f5-4c4d-8d42-1b6df9729157':'Entregado a titular',\n",
        "        'c505bc38-1215-48bf-9e6b-d78bce3dc2f2':'Cliente Solicito Reprogramación',\n",
        "        '8c15fdad-2f27-49eb-9967-f4fa94a366b1':'Entregado en tienda',\n",
        "        '04902a7e-116c-4083-82bb-2849e1928db3':'Cliente Ausente',\n",
        "        'fe8ac91f-0ead-4d84-b33c-aa094173d32b':'Domicilio Sin Acceso',\n",
        "        '2fee0a67-e6d8-4742-ac52-f8c4f0382543':'Rechazado Por Cliente',\n",
        "        '412375a8-cd64-4e8a-81be-5572ca883018':'Producto Dañado'\n",
        "        }\n",
        "    return mapping.get(observation, 'Otro')\n",
        "\n",
        "# Aplicar la función al DataFrame\n",
        "df_visits_selected['Observaciones'] = df_visits_selected['checkout_observation'].apply(map_observation_to_new_column)\n",
        "\n",
        "# Unir los DataFrames en el campo común 'vehicle'\n",
        "df_routes_vehicles = pd.merge(df_routes_selected, df_vehicles_selected, on='vehicle', how='inner')\n",
        "\n",
        "# Unir los DataFrames en el campo común 'vehicle'\n",
        "df_visits_routes_vehicles = pd.merge(df_visits_selected, df_routes_vehicles, on=('vehicle','driver' ,'route', 'planned_date'), how='left')\n",
        "\n",
        "project_id = 'bi-fcom-drmb-local-pe-sbx'\n",
        "!gcloud config set project {project_id}\n",
        "# Configuración del dataset y la tabla en BigQuery\n",
        "dataset_id = 'Pidgeotto_Devolucion'\n",
        "table_id = 'SimpliRoute_visits_IL'\n",
        "#table_id_2 = 'SimpliRoute_routes_IL'\n",
        "# Cliente de BigQuery\n",
        "client = bigquery.Client(project=project_id)\n",
        "# Cargar el DataFrame en BigQuery\n",
        "df_visits_routes_vehicles.to_gbq(destination_table=f'{dataset_id}.{table_id}', project_id=project_id, if_exists='replace')\n",
        "# Cargar el DataFrame en BigQuery\n",
        "#gdf.to_gbq(destination_table=f'{dataset_id}.{table_id_2}', project_id=project_id, if_exists='replace')\n",
        "# Mostrar el resultado\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRTQDHnCjErP",
        "outputId": "468bfca6-b8d9-461d-f065-11586f92622e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-d25c0c5f088c>:159: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['movimiento_fecha'] = pd.to_datetime(df['movimiento_fecha'], errors='coerce')\n",
            "<ipython-input-2-d25c0c5f088c>:159: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['movimiento_fecha'] = pd.to_datetime(df['movimiento_fecha'], errors='coerce')\n",
            "<ipython-input-2-d25c0c5f088c>:159: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['movimiento_fecha'] = pd.to_datetime(df['movimiento_fecha'], errors='coerce')\n",
            "<ipython-input-2-d25c0c5f088c>:160: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['estado_actual_fecha_hora'] = pd.to_datetime(df['estado_actual_fecha'] + \" \" + df['estado_actual_hora'],  errors='coerce')\n",
            "<ipython-input-2-d25c0c5f088c>:159: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['movimiento_fecha'] = pd.to_datetime(df['movimiento_fecha'], errors='coerce')\n",
            "<ipython-input-2-d25c0c5f088c>:159: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['movimiento_fecha'] = pd.to_datetime(df['movimiento_fecha'], errors='coerce')\n",
            "<ipython-input-2-d25c0c5f088c>:159: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['movimiento_fecha'] = pd.to_datetime(df['movimiento_fecha'], errors='coerce')\n",
            "<ipython-input-2-d25c0c5f088c>:159: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['movimiento_fecha'] = pd.to_datetime(df['movimiento_fecha'], errors='coerce')\n",
            "<ipython-input-2-d25c0c5f088c>:159: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['movimiento_fecha'] = pd.to_datetime(df['movimiento_fecha'], errors='coerce')\n",
            "<ipython-input-2-d25c0c5f088c>:159: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['movimiento_fecha'] = pd.to_datetime(df['movimiento_fecha'], errors='coerce')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 576.30it/s]\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "# Configurar cliente de BigQuery\n",
        "import gzip\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from google.colab import auth\n",
        "from google.colab import files # Esto solo es necesario si estás usando Google Colab\n",
        "from google.cloud import bigquery\n",
        "from google.cloud import storage\n",
        "import pandas as pd\n",
        "import os\n",
        "import gspread as gs\n",
        "import gspread_dataframe as gd\n",
        "\n",
        "import concurrent.futures\n",
        "from google.auth import default\n",
        "\n",
        "# URL y endpoint para producción\n",
        "BASE_URL_PROD = \"https://api.urbanoexpress.com.pe\"\n",
        "ENDPOINT_PROD = \"/api/ws/e-tracking\"\n",
        "\n",
        "# Credenciales de solicitud (reemplazar con tus credenciales reales)\n",
        "API_KEY = \"\"\n",
        "\n",
        "# Suprimir sólo las advertencias de InsecureRequestWarning\n",
        "warnings.filterwarnings('ignore', category=InsecureRequestWarning)\n",
        "\n",
        "# Autentificación\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "client = bigquery.Client(credentials=creds, project='bi-fcom-drmb-local-pe-sbx')\n",
        "\n",
        "# Consulta para obtener los números de guía\n",
        "query = \"\"\" ,
        "\"\"\"\n",
        "numeros_de_guia = client.query(query).to_dataframe()['tracking'].tolist()\n",
        "\n",
        "# Función para obtener información de seguimiento\n",
        "def obtener_informacion_tracking(api_key, guia):\n",
        "    url = f\"https://api.urbanoexpress.com.pe/api/ws/e-tracking\"\n",
        "    headers = {\n",
        "        'x-api-key': api_key,\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "    data = {\n",
        "        \"guia_ue\": guia,\n",
        "        \"tracking_number\": \"\"\n",
        "    }\n",
        "    try:\n",
        "        response = requests.post(url, headers=headers, json=data, verify=False)\n",
        "        response.raise_for_status()\n",
        "        return response.json()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "       # print(f\"Error en la solicitud para {guia}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Función para convertir datos a un DataFrame de pandas\n",
        "def convertir_a_dataframe(informacion):\n",
        "    if informacion is None:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Crear una lista para almacenar las filas de datos\n",
        "    rows = []\n",
        "\n",
        "    # Extraer información principal\n",
        "    info_principal = {\n",
        "        \"guia_ue\": informacion.get(\"guia_ue\", \"\"),\n",
        "        \"tracking_number\": informacion.get(\"tracking_number\", \"\"),\n",
        "\n",
        "        \"servicio_contrato\": informacion.get(\"servicio\", {}).get(\"contrato\", \"\"),\n",
        "        \"servicio_origen\": informacion.get(\"servicio\", {}).get(\"origen\", \"\"),\n",
        "        \"servicio_admitido\": informacion.get(\"servicio\", {}).get(\"admitido\", \"\"),\n",
        "\n",
        "        \"cliente_codigo\": informacion.get(\"cliente\", {}).get(\"codigo\", \"\"),\n",
        "        \"cliente_nombre\": informacion.get(\"cliente\", {}).get(\"nombre\", \"\"),\n",
        "        \"cliente_telefono\": informacion.get(\"cliente\", {}).get(\"telefono\", \"\"),\n",
        "\n",
        "        \"direccion_entrega\": informacion.get(\"direccion_entrega\", {}).get(\"direccion\", \"\"),\n",
        "        \"direccion_entrega_referencia\": informacion.get(\"direccion_entrega\", {}).get(\"referencia\", \"\"),\n",
        "        \"direccion_entrega_ciudad\": informacion.get(\"direccion_entrega\", {}).get(\"ciudad\", \"\"),\n",
        "        \"direccion_entrega_zona\": informacion.get(\"direccion_entrega\", {}).get(\"zona\", \"\"),\n",
        "        \"direccion_entrega_agencia\": informacion.get(\"direccion_entrega\", {}).get(\"agencia\", \"\"),\n",
        "\n",
        "        \"estado_actual_estado\": informacion.get(\"estado_actual\", {}).get(\"estado\", \"\"),\n",
        "        \"estado_actual_Detalle_Estado\": informacion.get(\"estado_actual\", {}).get(\"Detalle_Estado\", \"\"),\n",
        "        \"estado_actual_fecha\": informacion.get(\"estado_actual\", {}).get(\"fecha\", \"\") ,\n",
        "         \"estado_actual_hora\":informacion.get(\"estado_actual\", {}).get(\"hora\", \"\")\n",
        "    }\n",
        "\n",
        "    # Extraer información de movimientos\n",
        "    movimientos = informacion.get(\"movimiento\", [])\n",
        "    for movimiento in movimientos:\n",
        "        row = info_principal.copy()  # Copiar información principal\n",
        "        row.update({\n",
        "            \"movimiento_secuencia\": movimiento.get(\"secuencia\", \"\"),\n",
        "            \"movimiento_codigo\": movimiento.get(\"codigo\", \"\"),\n",
        "            \"movimiento_estado\": movimiento.get(\"estado\", \"\"),\n",
        "            \"movimiento_sub_estado\": movimiento.get(\"sub_estado\", \"\"),\n",
        "            \"movimiento_detalle_estado\": movimiento.get(\"detalle_estado\", \"\"),\n",
        "            \"movimiento_fecha\": movimiento.get(\"fecha\", \"\") + \" \" + movimiento.get(\"hora\", \"\"),\n",
        "            \"movimiento_apuntes\": movimiento.get(\"apuntes\", \"\"),\n",
        "            \"movimiento_dir_agencia\": movimiento.get(\"dir_agencia\", \"\"),\n",
        "            \"movimiento_n_visita\": movimiento.get(\"n_visita\", \"\")\n",
        "        })\n",
        "        rows.append(row)  # Agregar la fila a la lista\n",
        "\n",
        "    # Convertir la lista de filas a un DataFrame de pandas\n",
        "    df = pd.DataFrame(rows)\n",
        "    # Especificar el formato de las fechas y horas\n",
        "    date_format = \"%Y-%m-%d %H:%M:%S\"\n",
        "\n",
        "    # Convertir la columna de fecha y hora a datetime\n",
        "    if not df.empty:\n",
        "        df['movimiento_fecha'] = pd.to_datetime(df['movimiento_fecha'], errors='coerce')\n",
        "        df['estado_actual_fecha_hora'] = pd.to_datetime(df['estado_actual_fecha'] + \" \" + df['estado_actual_hora'],  errors='coerce')\n",
        "\n",
        "        # Eliminar las columnas originales de fecha y hora si ya no son necesarias\n",
        "        df = df.drop(columns=['estado_actual_fecha', 'estado_actual_hora'])\n",
        "\n",
       
        "    return df\n",
        "# Procesamiento en paralelo usando ThreadPoolExecutor\n",
        "def procesar_tracking(api_key, numeros_de_guia, max_workers=30):\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        future_to_guia = {executor.submit(obtener_informacion_tracking, api_key, guia): guia for guia in numeros_de_guia}\n",
        "        resultados = []\n",
        "        for future in concurrent.futures.as_completed(future_to_guia):\n",
        "            guia = future_to_guia[future]\n",
        "            try:\n",
        "                resultado = future.result()\n",
        "                if resultado:  # Solo agregar resultados válidos\n",
        "                    resultados.append(resultado)\n",
        "            except Exception as e:\n",
        "                print(f\"Error al procesar la información de tracking para {guia}: {e}\")\n",
        "    return resultados\n",
        "\n",
        "resultados = procesar_tracking(API_KEY, numeros_de_guia, max_workers=30)\n",
        "\n",
        "# Convertir resultados a DataFrame\n",
        "df_total = pd.concat([convertir_a_dataframe(r) for r in resultados if r], ignore_index=True)\n",
        "\n",
        "# Guarda el DataFrame como un archivo Excel\n",
        "#archivo_excel = 'informacion_tracking_total.xlsx'\n",
        "#df_total.to_excel(archivo_excel, index=False)\n",
        "\n",
        "# Comprimir el archivo Excel utilizando gzip\n",
        "#archivo_comprimido = 'informacion_tracking_total.xlsx.gz'\n",
        "#with open(archivo_excel, 'rb') as f_in:\n",
        "#    with gzip.open(archivo_comprimido, 'wb') as f_out:\n",
        "#        shutil.copyfileobj(f_in, f_out)\n",
        "\n",
        "# Descargar el archivo Excel comprimido\n",
        "#files.download(archivo_comprimido)\n",
        "\n",
        "project_id = 'bi-fcom-drmb-local-pe-sbx'\n",
        "!gcloud config set project {project_id}\n",
        "# Configuración del dataset y la tabla en BigQuery\n",
        "dataset_id = 'Pidgeotto_Devolucion'\n",
        "table_id = 'URBANO_IL'\n",
        "\n",
        "# Cliente de BigQuery\n",
        "client = bigquery.Client(project=project_id)\n",
        "# Cargar el DataFrame en BigQuery\n",
        "df_total.to_gbq(destination_table=f'{dataset_id}.{table_id}', project_id=project_id, if_exists='replace')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPt9BtzXABIH55IgWH+CTHY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
